{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dConall/Monopoly/blob/master/Homework_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FEP1m-gn-Cg2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ]
    },
    {
      "metadata": {
        "id": "3SGJGqDH-Cg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### To do list\n",
        "* Preprocessing\n",
        "    * Tokenisation (Are we able to keep words such as wi-fi as one token instead of two tokens wi and fi)\n",
        "    * Remove stopwords, punctuation, numbers (Or covert to textual representations)\n",
        "    * Stemming\n",
        "    * Lemmatization\n",
        "    * get noun tokens\n",
        "    * bi-grams/tri-grams\n",
        "    * Label Encoding\n",
        "    * Split training into train and validation set\n",
        "    * Could Someone convert the preprocessing into one function. That way we can use it again when preprocessing the test data\n",
        "* Feature Engineering\n",
        "    * TD-IDF\n",
        "    * Word Embeddings\n",
        "    * Count vectors\n",
        "    * Bag of Words\n",
        "* Classification\n",
        "    * Naive bayes\n",
        "    * SVM\n",
        "    * Logistic regression\n",
        "    * random forest"
      ]
    },
    {
      "metadata": {
        "id": "QPkj8_Da-Cg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f83b7efb-ddf1-4825-d7ab-f0c1ea36e1b4"
      },
      "cell_type": "code",
      "source": [
        "##importing libraries\n",
        "import numpy as np\n",
        "import nltk, io, os\n",
        "from nltk import ngrams\n",
        "import nltk\n",
        "nltk.download('stopwords'), nltk.download('averaged_perceptron_tagger'), nltk.download('wordnet')\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZNoMadMF-Cg9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##importing dataset\n",
        "raw_trainset = pd.read_csv('trainingset.csv',sep='^',header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TNB2jFh3-Cg_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "839e3f9d-6c02-403e-c138-8fd312fff577"
      },
      "cell_type": "code",
      "source": [
        "raw_trainset.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>French boss to leave EADS The French co-head o...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gamers could drive high-definition TV, films, ...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stalemate in pension strike talks Talks aimed ...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Johnny and Denise lose Passport Johnny Vaughan...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tautou 'to star in Da Vinci film' French actre...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content       category\n",
              "0  French boss to leave EADS The French co-head o...       business\n",
              "1  Gamers could drive high-definition TV, films, ...           tech\n",
              "2  Stalemate in pension strike talks Talks aimed ...       politics\n",
              "3  Johnny and Denise lose Passport Johnny Vaughan...  entertainment\n",
              "4  Tautou 'to star in Da Vinci film' French actre...  entertainment"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "kJiD5qde-ChF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "\n",
        "Removing  punctuation, numbers, and stopwords from the texts."
      ]
    },
    {
      "metadata": {
        "id": "G9Vsl8jE-ChH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##adding new column to dataset for tokens\n",
        "temp = pd.DataFrame([],columns=['tokens'])\n",
        "raw_trainset = raw_trainset.join(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kN8Voyh4-ChJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fd4c8245-bcf0-4622-f807-3024f30ca686"
      },
      "cell_type": "code",
      "source": [
        "##importing tokenizer and stopword dictionary\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "for index, row in raw_trainset.iterrows():\n",
        "    \n",
        "    ##getting token words from the articles while removing punctuation\n",
        "    pattern = r'\\w+'\n",
        "    tokenizer = RegexpTokenizer(pattern)\n",
        "    token_words = tokenizer.tokenize(row['content'].replace(\"-\", \"_\")) # -> Replacing hyphens with underscores so that words like\n",
        "                                                                       #    Co-Head, Wi-Fi, High-Definition etc. stay together\n",
        "    \n",
        "    ##removong numbers\n",
        "    token_words = ([word for word in token_words if not word.isdigit()])\n",
        "    \n",
        "    ##removing stopwords\n",
        "    token_words = [word for word in token_words if not word in stopwords] \n",
        "    \n",
        "    ##Stemming\n",
        "    porter = PorterStemmer()\n",
        "    token_words = [porter.stem(word) for word in token_words]\n",
        "    \n",
        "    ##Transfer tag function\n",
        "    def transfer_tag(treebank_tag):\n",
        "        if treebank_tag.startswith('j' or 'J'):\n",
        "            return 'a'\n",
        "        elif treebank_tag.startswith('v' or 'V'):\n",
        "            return 'v'\n",
        "        elif treebank_tag.startswith('n' or 'N'):\n",
        "            return 'n'\n",
        "        elif treebank_tag.startswith('r' or 'R'):\n",
        "            return 'r'\n",
        "        else:\n",
        "            # As default pos in lemmatization is Noun\n",
        "            return 'n'\n",
        "        \n",
        "    ##Lemmatization\n",
        "    wnl = WordNetLemmatizer()\n",
        "\n",
        "    lemma_words = []\n",
        "    for word, tag in nltk.pos_tag(token_words):\n",
        "        firstletter = tag[0].lower() # -> get the first letter of tag and put them decapitalized form\n",
        "        wtag = transfer_tag(firstletter) # -> extract the word's tag (noun, verb, adverb, adjective)\n",
        "        if not wtag:\n",
        "            lemma_words.extend([word])\n",
        "        else:\n",
        "            lemma_words.extend([wnl.lemmatize(word, wtag)])\n",
        "    \n",
        "    raw_trainset.set_value(index, 'tokens', lemma_words)\n",
        "\n",
        "raw_trainset.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>category</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>French boss to leave EADS The French co-head o...</td>\n",
              "      <td>business</td>\n",
              "      <td>[french, bos, leav, ead, the, french, co_head,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gamers could drive high-definition TV, films, ...</td>\n",
              "      <td>tech</td>\n",
              "      <td>[gamer, could, drive, high_definit, TV, film, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stalemate in pension strike talks Talks aimed ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>[stalem, pension, strike, talk, talk, aim, ave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Johnny and Denise lose Passport Johnny Vaughan...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>[johnni, denis, lose, passport, johnni, vaugha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tautou 'to star in Da Vinci film' French actre...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>[tautou, star, Da, vinci, film, french, actres...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content       category  \\\n",
              "0  French boss to leave EADS The French co-head o...       business   \n",
              "1  Gamers could drive high-definition TV, films, ...           tech   \n",
              "2  Stalemate in pension strike talks Talks aimed ...       politics   \n",
              "3  Johnny and Denise lose Passport Johnny Vaughan...  entertainment   \n",
              "4  Tautou 'to star in Da Vinci film' French actre...  entertainment   \n",
              "\n",
              "                                              tokens  \n",
              "0  [french, bos, leav, ead, the, french, co_head,...  \n",
              "1  [gamer, could, drive, high_definit, TV, film, ...  \n",
              "2  [stalem, pension, strike, talk, talk, aim, ave...  \n",
              "3  [johnni, denis, lose, passport, johnni, vaugha...  \n",
              "4  [tautou, star, Da, vinci, film, french, actres...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "vdOoTS4S-ChN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#One hot encoding the label \n",
        "trainset = pd.get_dummies(raw_trainset, columns=[\"category\"]).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OZk9yF0J-ChQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "d50ea672-cb26-413e-c4b4-bd23c2581b8d"
      },
      "cell_type": "code",
      "source": [
        "trainset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>tokens</th>\n",
              "      <th>category_business</th>\n",
              "      <th>category_entertainment</th>\n",
              "      <th>category_politics</th>\n",
              "      <th>category_sport</th>\n",
              "      <th>category_tech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>French boss to leave EADS The French co-head o...</td>\n",
              "      <td>[French, boss, leave, EADS, The, French, co, h...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gamers could drive high-definition TV, films, ...</td>\n",
              "      <td>[Gamers, could, drive, high, definition, TV, f...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stalemate in pension strike talks Talks aimed ...</td>\n",
              "      <td>[Stalemate, pension, strike, talks, Talks, aim...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Johnny and Denise lose Passport Johnny Vaughan...</td>\n",
              "      <td>[Johnny, Denise, lose, Passport, Johnny, Vaugh...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tautou 'to star in Da Vinci film' French actre...</td>\n",
              "      <td>[Tautou, star, Da, Vinci, film, French, actres...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  \\\n",
              "0  French boss to leave EADS The French co-head o...   \n",
              "1  Gamers could drive high-definition TV, films, ...   \n",
              "2  Stalemate in pension strike talks Talks aimed ...   \n",
              "3  Johnny and Denise lose Passport Johnny Vaughan...   \n",
              "4  Tautou 'to star in Da Vinci film' French actre...   \n",
              "\n",
              "                                              tokens  category_business  \\\n",
              "0  [French, boss, leave, EADS, The, French, co, h...                  1   \n",
              "1  [Gamers, could, drive, high, definition, TV, f...                  0   \n",
              "2  [Stalemate, pension, strike, talks, Talks, aim...                  0   \n",
              "3  [Johnny, Denise, lose, Passport, Johnny, Vaugh...                  0   \n",
              "4  [Tautou, star, Da, Vinci, film, French, actres...                  0   \n",
              "\n",
              "   category_entertainment  category_politics  category_sport  category_tech  \n",
              "0                       0                  0               0              0  \n",
              "1                       0                  0               0              1  \n",
              "2                       0                  1               0              0  \n",
              "3                       1                  0               0              0  \n",
              "4                       1                  0               0              0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "GvHfPuMb-ChU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}